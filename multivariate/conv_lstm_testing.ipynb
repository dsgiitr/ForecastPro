{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def split_df(df, window_size, n_series, split=0.75):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np)-window_size):\n",
    "        row = [[a] for a in df_as_np[i:i+window_size]]\n",
    "        X.append(row)\n",
    "        label = df_as_np[i+window_size]\n",
    "        y.append(label)\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    X=X.reshape(-1,window_size,n_series)\n",
    "    X_train=X[:int(split*len(X))]\n",
    "    y_train=y[:int(split*len(X))]\n",
    "    X_test=X[int(split*len(X)):]\n",
    "    y_test=y[int(split*len(X)):]\n",
    "\n",
    "    return X_train,y_train, X_test, y_test\n",
    "\n",
    "\n",
    "class ConvLSTM(Model):\n",
    "    def __init__(self, \n",
    "                 time_steps, \n",
    "                 n_series,\n",
    "                 forecast_steps,\n",
    "                 epochs=60,\n",
    "                 ):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.conv1d = Conv1D(32, kernel_size=2)\n",
    "        self.lstm = LSTM(64)\n",
    "        self.dense1 = Dense(32, activation='relu')\n",
    "        self.dense2 = Dense(16, activation='relu')\n",
    "        self.dense3 = Dense(n_series, activation='linear')\n",
    "        self.history= None\n",
    "        self.forecast_setps=forecast_steps\n",
    "        self.y_test=None\n",
    "        self.n_series=n_series\n",
    "        self.epochs=epochs\n",
    "        self.time_steps=time_steps\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1d(inputs)\n",
    "        x = self.lstm(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        outputs = self.dense3(x)\n",
    "        return outputs\n",
    "\n",
    "    def train(self, X_train, y_train, X_test, y_test):\n",
    "        self.y_test=y_test\n",
    "        cp1 = tf.keras.callbacks.ModelCheckpoint('conv_lstm_checkpoint/', save_best_only=True)\n",
    "        self.compile(loss=tf.keras.losses.MeanSquaredError(), \n",
    "                     optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), \n",
    "                     metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "                     )\n",
    "        self.history = self.fit(X_train, \n",
    "                                y_train, \n",
    "                                validation_data=(X_test, y_test), \n",
    "                                epochs=self.epochs,\n",
    "                                callbacks=[cp1])\n",
    "    \n",
    "    def prediction_summary(self, X_test, summary=False):\n",
    "        preds = self.predict(X_test)\n",
    "        if summary==True:\n",
    "            plt.plot(preds[:100, 0], label='preds')\n",
    "            plt.plot(self.y_test[:100, 0], label='actual')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(self.history.history['loss'])\n",
    "            plt.plot(self.history.history['val_loss'])\n",
    "            plt.title('model loss')\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'val'], loc='upper right')\n",
    "            plt.show()\n",
    "        return preds,self.y_test\n",
    "\n",
    "    def forecast(self, X_test, forecast_steps, plot_forecast=True):\n",
    "        last_batch = X_test[-1]\n",
    "        forecast = []\n",
    "        for step in range(forecast_steps):\n",
    "            pred = self.predict(np.array(last_batch).reshape(1, self.time_steps, self.n_series))\n",
    "            forecast.append(pred)\n",
    "            last_batch = np.append(last_batch[1:,:], pred, axis=0)\n",
    "        forecast = np.array(forecast)\n",
    "        final_forecast = forecast.reshape(forecast_steps, self.n_series)\n",
    "        if(plot_forecast==True):\n",
    "            chart_df=pd.DataFrame(np.append(self.y_test[-40:,:], final_forecast, axis=0).reshape(40+forecast_steps,-1))\n",
    "            chart_df.iloc[:100,1].plot(label='actual')\n",
    "            chart_df.iloc[100:,1].plot(label='forecast')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            return chart_df\n",
    "        return final_forecast\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.578554\n",
       "1     0.466669\n",
       "2     0.842208\n",
       "3     0.560933\n",
       "4     0.493566\n",
       "5     0.808935\n",
       "6     0.706668\n",
       "7     0.753308\n",
       "8     0.050264\n",
       "9     0.648565\n",
       "10    0.444668\n",
       "11    0.788406\n",
       "12    0.658160\n",
       "13    0.456331\n",
       "14    0.958175\n",
       "15    0.583654\n",
       "16    0.354045\n",
       "17    0.555175\n",
       "18    0.611073\n",
       "19    0.511128\n",
       "20    0.648392\n",
       "21    0.716654\n",
       "22    0.713932\n",
       "23    0.549496\n",
       "24    0.537941\n",
       "25    0.292859\n",
       "26    0.719034\n",
       "27    0.703372\n",
       "28    0.628915\n",
       "29    0.149350\n",
       "30    0.525731\n",
       "31    0.745401\n",
       "32    0.592261\n",
       "33    0.272508\n",
       "34    0.634716\n",
       "35    0.364415\n",
       "36    0.628057\n",
       "37    0.353491\n",
       "38    0.630781\n",
       "39    0.733879\n",
       "40    0.507634\n",
       "41    0.509659\n",
       "42    0.365453\n",
       "43    0.946911\n",
       "44    0.664385\n",
       "45    0.715443\n",
       "46    0.656107\n",
       "47    0.577320\n",
       "Name: 2300, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-700,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"large_portfolio.csv\")\n",
    "df=df.drop('Date', axis=1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "df=pd.DataFrame(scaler.fit_transform(df))\n",
    "X_train,y_train, X_test, y_test=split_df(df=df.iloc[-200:,:6],window_size=14, n_series=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 7s - loss: 0.4473 - root_mean_squared_error: 0.6688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 1s/step - loss: 0.2366 - root_mean_squared_error: 0.4864 - val_loss: 0.0757 - val_root_mean_squared_error: 0.2751\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0300 - root_mean_squared_error: 0.1733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 982ms/step - loss: 0.0300 - root_mean_squared_error: 0.1733 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0073 - root_mean_squared_error: 0.0854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 1s/step - loss: 0.0073 - root_mean_squared_error: 0.0854 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1153\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0045 - root_mean_squared_error: 0.0671 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0062 - root_mean_squared_error: 0.0790 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0042 - root_mean_squared_error: 0.0649 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0028 - root_mean_squared_error: 0.0526 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0026 - root_mean_squared_error: 0.0505 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0027 - root_mean_squared_error: 0.0519 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1324\n",
      "Epoch 10/60\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0036 - root_mean_squared_error: 0.0600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 898ms/step - loss: 0.0027 - root_mean_squared_error: 0.0515 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0022 - root_mean_squared_error: 0.0470"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 1s/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 12/60\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0020 - root_mean_squared_error: 0.0448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 928ms/step - loss: 0.0026 - root_mean_squared_error: 0.0508 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0875\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0026 - root_mean_squared_error: 0.0509 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0911\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0019 - root_mean_squared_error: 0.0437 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0942\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1035\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0019 - root_mean_squared_error: 0.0435 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0020 - root_mean_squared_error: 0.0444 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994\n",
      "Epoch 19/60\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0014 - root_mean_squared_error: 0.0379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 1s/step - loss: 0.0015 - root_mean_squared_error: 0.0393 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0817\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0014 - root_mean_squared_error: 0.0372 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0013 - root_mean_squared_error: 0.0363 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0863\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0011 - root_mean_squared_error: 0.0337 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 24/60\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - root_mean_squared_error: 0.0340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 919ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0012 - root_mean_squared_error: 0.0339 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0803\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0011 - root_mean_squared_error: 0.0327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 957ms/step - loss: 0.0011 - root_mean_squared_error: 0.0327 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810\n",
      "Epoch 28/60\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.0013 - root_mean_squared_error: 0.0364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 900ms/step - loss: 0.0014 - root_mean_squared_error: 0.0372 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0691\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0017 - root_mean_squared_error: 0.0417 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0015 - root_mean_squared_error: 0.0385 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0011 - root_mean_squared_error: 0.0338 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0011 - root_mean_squared_error: 0.0337 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0016 - root_mean_squared_error: 0.0402 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0012 - root_mean_squared_error: 0.0344 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9483e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0010 - root_mean_squared_error: 0.0318 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5289e-04 - root_mean_squared_error: 0.0309 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 41/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 9.2778e-04 - root_mean_squared_error: 0.0305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 1s/step - loss: 9.2778e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0011 - root_mean_squared_error: 0.0326 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0718\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - root_mean_squared_error: 0.0328 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - root_mean_squared_error: 0.0366 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 45/60\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.0900e-04 - root_mean_squared_error: 0.0301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 944ms/step - loss: 0.0011 - root_mean_squared_error: 0.0327 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5640e-04 - root_mean_squared_error: 0.0309 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0010 - root_mean_squared_error: 0.0321 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0683\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0011 - root_mean_squared_error: 0.0338 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 51/60\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8505e-04 - root_mean_squared_error: 0.0297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 1s/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0013 - root_mean_squared_error: 0.0355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: conv_lstm_checkpoint\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 1s/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0576\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0013 - root_mean_squared_error: 0.0367 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2934e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7210e-04 - root_mean_squared_error: 0.0295 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0695\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6519e-04 - root_mean_squared_error: 0.0294 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4946e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2799e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7847e-04 - root_mean_squared_error: 0.0296 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0606\n",
      "Model: \"conv_lstm_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           multiple                  416       \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               multiple                  24832     \n",
      "                                                                 \n",
      " dense_21 (Dense)            multiple                  2080      \n",
      "                                                                 \n",
      " dense_22 (Dense)            multiple                  528       \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,958\n",
      "Trainable params: 27,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 330 into shape (115,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23476/2585821990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Assuming you have test data and forecast_steps: X_test, forecast_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mfinal_forecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_lstm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_forecast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_forecast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23476/1915480222.py\u001b[0m in \u001b[0;36mforecast\u001b[1;34m(self, X_test, forecast_steps, plot_forecast)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mfinal_forecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_series\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_forecast\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mchart_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_forecast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mforecast_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[0mchart_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'actual'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mchart_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'forecast'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 330 into shape (115,newaxis)"
     ]
    }
   ],
   "source": [
    "time_steps = 14\n",
    "n_series = 6\n",
    "\n",
    "conv_lstm_model = ConvLSTM(time_steps, n_series, forecast_steps=15)\n",
    "conv_lstm_model.train(X_train,y_train, X_test, y_test)\n",
    "\n",
    "conv_lstm_model.summary()\n",
    "\n",
    "\n",
    "# Assuming you have test data and forecast_steps: X_test, forecast_steps\n",
    "final_forecast = conv_lstm_model.forecast(X_test=X_test, forecast_steps=15, plot_forecast=True)\n",
    "print(final_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[-40:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.899994</td>\n",
       "      <td>122.230003</td>\n",
       "      <td>123.010002</td>\n",
       "      <td>323.940002</td>\n",
       "      <td>140.669998</td>\n",
       "      <td>225.089996</td>\n",
       "      <td>158.500000</td>\n",
       "      <td>145.339996</td>\n",
       "      <td>108.769997</td>\n",
       "      <td>16.040001</td>\n",
       "      <td>...</td>\n",
       "      <td>171.479996</td>\n",
       "      <td>81.885236</td>\n",
       "      <td>512.500000</td>\n",
       "      <td>91.280745</td>\n",
       "      <td>790.697485</td>\n",
       "      <td>132.009995</td>\n",
       "      <td>197.869995</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>173.070007</td>\n",
       "      <td>44.291095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181.500000</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>124.080002</td>\n",
       "      <td>324.989990</td>\n",
       "      <td>140.350006</td>\n",
       "      <td>223.639999</td>\n",
       "      <td>160.419998</td>\n",
       "      <td>145.679993</td>\n",
       "      <td>108.459999</td>\n",
       "      <td>16.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>82.490465</td>\n",
       "      <td>518.190002</td>\n",
       "      <td>90.886021</td>\n",
       "      <td>801.529758</td>\n",
       "      <td>132.949997</td>\n",
       "      <td>197.630005</td>\n",
       "      <td>74.860001</td>\n",
       "      <td>173.429993</td>\n",
       "      <td>44.467395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181.270004</td>\n",
       "      <td>122.790001</td>\n",
       "      <td>124.019997</td>\n",
       "      <td>328.579987</td>\n",
       "      <td>141.070007</td>\n",
       "      <td>224.410004</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>105.809998</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>170.839996</td>\n",
       "      <td>83.184994</td>\n",
       "      <td>517.280029</td>\n",
       "      <td>91.330092</td>\n",
       "      <td>806.821601</td>\n",
       "      <td>131.960007</td>\n",
       "      <td>198.210007</td>\n",
       "      <td>74.410004</td>\n",
       "      <td>171.529999</td>\n",
       "      <td>44.320476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182.800003</td>\n",
       "      <td>124.980003</td>\n",
       "      <td>128.119995</td>\n",
       "      <td>334.470001</td>\n",
       "      <td>140.479996</td>\n",
       "      <td>225.619995</td>\n",
       "      <td>159.729996</td>\n",
       "      <td>144.509995</td>\n",
       "      <td>107.379997</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>171.309998</td>\n",
       "      <td>84.504608</td>\n",
       "      <td>522.020020</td>\n",
       "      <td>91.320221</td>\n",
       "      <td>856.566582</td>\n",
       "      <td>134.660004</td>\n",
       "      <td>198.500000</td>\n",
       "      <td>73.900002</td>\n",
       "      <td>176.559998</td>\n",
       "      <td>44.594725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.369995</td>\n",
       "      <td>123.099998</td>\n",
       "      <td>126.699997</td>\n",
       "      <td>334.339996</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>223.740005</td>\n",
       "      <td>161.600006</td>\n",
       "      <td>145.309998</td>\n",
       "      <td>107.449997</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>173.660004</td>\n",
       "      <td>87.838357</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>92.741246</td>\n",
       "      <td>851.364321</td>\n",
       "      <td>134.639999</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>74.900002</td>\n",
       "      <td>175.820007</td>\n",
       "      <td>44.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>183.960007</td>\n",
       "      <td>123.139999</td>\n",
       "      <td>125.209999</td>\n",
       "      <td>337.480011</td>\n",
       "      <td>140.589996</td>\n",
       "      <td>222.020004</td>\n",
       "      <td>162.050003</td>\n",
       "      <td>147.169998</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>175.460007</td>\n",
       "      <td>87.262888</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>92.464932</td>\n",
       "      <td>879.723200</td>\n",
       "      <td>134.919998</td>\n",
       "      <td>201.250000</td>\n",
       "      <td>73.739998</td>\n",
       "      <td>176.240005</td>\n",
       "      <td>44.119999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>186.729996</td>\n",
       "      <td>125.930000</td>\n",
       "      <td>127.709999</td>\n",
       "      <td>351.320007</td>\n",
       "      <td>143.050003</td>\n",
       "      <td>226.449997</td>\n",
       "      <td>164.479996</td>\n",
       "      <td>148.919998</td>\n",
       "      <td>106.360001</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>179.990005</td>\n",
       "      <td>87.590308</td>\n",
       "      <td>530.099976</td>\n",
       "      <td>93.501090</td>\n",
       "      <td>884.567439</td>\n",
       "      <td>139.039993</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>179.449997</td>\n",
       "      <td>44.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>184.410004</td>\n",
       "      <td>122.930000</td>\n",
       "      <td>124.970001</td>\n",
       "      <td>339.309998</td>\n",
       "      <td>142.610001</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>164.259995</td>\n",
       "      <td>149.750000</td>\n",
       "      <td>104.680000</td>\n",
       "      <td>16.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>176.460007</td>\n",
       "      <td>87.828431</td>\n",
       "      <td>521.950012</td>\n",
       "      <td>94.497780</td>\n",
       "      <td>858.088455</td>\n",
       "      <td>136.059998</td>\n",
       "      <td>202.649994</td>\n",
       "      <td>75.629997</td>\n",
       "      <td>174.940002</td>\n",
       "      <td>44.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>184.899994</td>\n",
       "      <td>122.400002</td>\n",
       "      <td>125.639999</td>\n",
       "      <td>336.369995</td>\n",
       "      <td>142.899994</td>\n",
       "      <td>226.119995</td>\n",
       "      <td>163.580002</td>\n",
       "      <td>148.259995</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>174.130005</td>\n",
       "      <td>88.195544</td>\n",
       "      <td>517.909973</td>\n",
       "      <td>93.747798</td>\n",
       "      <td>860.000000</td>\n",
       "      <td>135.570007</td>\n",
       "      <td>199.289993</td>\n",
       "      <td>74.449997</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>43.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>183.740005</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>125.309998</td>\n",
       "      <td>334.119995</td>\n",
       "      <td>142.309998</td>\n",
       "      <td>226.360001</td>\n",
       "      <td>163.899994</td>\n",
       "      <td>150.350006</td>\n",
       "      <td>102.839996</td>\n",
       "      <td>15.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>172.160004</td>\n",
       "      <td>88.010002</td>\n",
       "      <td>520.690002</td>\n",
       "      <td>95.220001</td>\n",
       "      <td>845.090027</td>\n",
       "      <td>134.380005</td>\n",
       "      <td>201.960007</td>\n",
       "      <td>76.070000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>44.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>185.550003</td>\n",
       "      <td>121.379997</td>\n",
       "      <td>129.110001</td>\n",
       "      <td>334.359985</td>\n",
       "      <td>138.539993</td>\n",
       "      <td>227.220001</td>\n",
       "      <td>166.110001</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>102.589996</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>169.600006</td>\n",
       "      <td>87.239998</td>\n",
       "      <td>523.130005</td>\n",
       "      <td>95.669998</td>\n",
       "      <td>834.010010</td>\n",
       "      <td>133.699997</td>\n",
       "      <td>199.130005</td>\n",
       "      <td>75.290001</td>\n",
       "      <td>169.910004</td>\n",
       "      <td>43.869999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>186.830002</td>\n",
       "      <td>120.760002</td>\n",
       "      <td>129.330002</td>\n",
       "      <td>333.720001</td>\n",
       "      <td>138.869995</td>\n",
       "      <td>229.440002</td>\n",
       "      <td>164.979996</td>\n",
       "      <td>148.100006</td>\n",
       "      <td>102.199997</td>\n",
       "      <td>15.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>169.220001</td>\n",
       "      <td>87.349998</td>\n",
       "      <td>524.400024</td>\n",
       "      <td>96.220001</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>133.100006</td>\n",
       "      <td>200.300003</td>\n",
       "      <td>74.089996</td>\n",
       "      <td>168.490005</td>\n",
       "      <td>43.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>185.889999</td>\n",
       "      <td>117.080002</td>\n",
       "      <td>128.630005</td>\n",
       "      <td>331.859985</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>227.479996</td>\n",
       "      <td>163.679993</td>\n",
       "      <td>148.440002</td>\n",
       "      <td>104.050003</td>\n",
       "      <td>15.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>173.389999</td>\n",
       "      <td>86.879997</td>\n",
       "      <td>522.650024</td>\n",
       "      <td>96.879997</td>\n",
       "      <td>828.679993</td>\n",
       "      <td>132.490005</td>\n",
       "      <td>202.559998</td>\n",
       "      <td>74.559998</td>\n",
       "      <td>169.830002</td>\n",
       "      <td>44.160000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0   177.899994  122.230003  123.010002  323.940002  140.669998  225.089996   \n",
       "1   181.500000  122.250000  124.080002  324.989990  140.350006  223.639999   \n",
       "2   181.270004  122.790001  124.019997  328.579987  141.070007  224.410004   \n",
       "3   182.800003  124.980003  128.119995  334.470001  140.479996  225.619995   \n",
       "4   183.369995  123.099998  126.699997  334.339996  143.000000  223.740005   \n",
       "5   183.960007  123.139999  125.209999  337.480011  140.589996  222.020004   \n",
       "6   186.729996  125.930000  127.709999  351.320007  143.050003  226.449997   \n",
       "7   184.410004  122.930000  124.970001  339.309998  142.610001  227.000000   \n",
       "8   184.899994  122.400002  125.639999  336.369995  142.899994  226.119995   \n",
       "9   183.740005  120.000000  125.309998  334.119995  142.309998  226.360001   \n",
       "10  185.550003  121.379997  129.110001  334.359985  138.539993  227.220001   \n",
       "11  186.830002  120.760002  129.330002  333.720001  138.869995  229.440002   \n",
       "12  185.889999  117.080002  128.630005  331.859985  139.000000  227.479996   \n",
       "\n",
       "            6           7           8          9   ...          38         39  \\\n",
       "0   158.500000  145.339996  108.769997  16.040001  ...  171.479996  81.885236   \n",
       "1   160.419998  145.679993  108.459999  16.010000  ...  171.000000  82.490465   \n",
       "2   160.000000  147.000000  105.809998  15.950000  ...  170.839996  83.184994   \n",
       "3   159.729996  144.509995  107.379997  15.800000  ...  171.309998  84.504608   \n",
       "4   161.600006  145.309998  107.449997  15.900000  ...  173.660004  87.838357   \n",
       "5   162.050003  147.169998  105.500000  15.880000  ...  175.460007  87.262888   \n",
       "6   164.479996  148.919998  106.360001  16.100000  ...  179.990005  87.590308   \n",
       "7   164.259995  149.750000  104.680000  16.020000  ...  176.460007  87.828431   \n",
       "8   163.580002  148.259995  102.500000  15.700000  ...  174.130005  88.195544   \n",
       "9   163.899994  150.350006  102.839996  15.570000  ...  172.160004  88.010002   \n",
       "10  166.110001  150.250000  102.589996  15.630000  ...  169.600006  87.239998   \n",
       "11  164.979996  148.100006  102.199997  15.460000  ...  169.220001  87.349998   \n",
       "12  163.679993  148.440002  104.050003  15.550000  ...  173.389999  86.879997   \n",
       "\n",
       "            40         41          42          43          44         45  \\\n",
       "0   512.500000  91.280745  790.697485  132.009995  197.869995  74.480003   \n",
       "1   518.190002  90.886021  801.529758  132.949997  197.630005  74.860001   \n",
       "2   517.280029  91.330092  806.821601  131.960007  198.210007  74.410004   \n",
       "3   522.020020  91.320221  856.566582  134.660004  198.500000  73.900002   \n",
       "4   525.000000  92.741246  851.364321  134.639999  202.000000  74.900002   \n",
       "5   529.000000  92.464932  879.723200  134.919998  201.250000  73.739998   \n",
       "6   530.099976  93.501090  884.567439  139.039993  205.000000  74.750000   \n",
       "7   521.950012  94.497780  858.088455  136.059998  202.649994  75.629997   \n",
       "8   517.909973  93.747798  860.000000  135.570007  199.289993  74.449997   \n",
       "9   520.690002  95.220001  845.090027  134.380005  201.960007  76.070000   \n",
       "10  523.130005  95.669998  834.010010  133.699997  199.130005  75.290001   \n",
       "11  524.400024  96.220001  825.000000  133.100006  200.300003  74.089996   \n",
       "12  522.650024  96.879997  828.679993  132.490005  202.559998  74.559998   \n",
       "\n",
       "            46         47  \n",
       "0   173.070007  44.291095  \n",
       "1   173.429993  44.467395  \n",
       "2   171.529999  44.320476  \n",
       "3   176.559998  44.594725  \n",
       "4   175.820007  44.900002  \n",
       "5   176.240005  44.119999  \n",
       "6   179.449997  44.220001  \n",
       "7   174.940002  44.029999  \n",
       "8   172.500000  43.470001  \n",
       "9   170.000000  44.099998  \n",
       "10  169.910004  43.869999  \n",
       "11  168.490005  43.500000  \n",
       "12  169.830002  44.160000  \n",
       "\n",
       "[13 rows x 48 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test[-1][1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178.440002</td>\n",
       "      <td>126.970001</td>\n",
       "      <td>127.010002</td>\n",
       "      <td>331.649994</td>\n",
       "      <td>139.550003</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>158.100006</td>\n",
       "      <td>144.009995</td>\n",
       "      <td>106.790001</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>167.350006</td>\n",
       "      <td>83.135394</td>\n",
       "      <td>514.510010</td>\n",
       "      <td>90.649184</td>\n",
       "      <td>785.634520</td>\n",
       "      <td>132.750000</td>\n",
       "      <td>196.960007</td>\n",
       "      <td>73.639999</td>\n",
       "      <td>171.169998</td>\n",
       "      <td>43.801366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177.899994</td>\n",
       "      <td>122.230003</td>\n",
       "      <td>123.010002</td>\n",
       "      <td>323.940002</td>\n",
       "      <td>140.669998</td>\n",
       "      <td>225.089996</td>\n",
       "      <td>158.500000</td>\n",
       "      <td>145.339996</td>\n",
       "      <td>108.769997</td>\n",
       "      <td>16.040001</td>\n",
       "      <td>...</td>\n",
       "      <td>171.479996</td>\n",
       "      <td>81.885236</td>\n",
       "      <td>512.500000</td>\n",
       "      <td>91.280745</td>\n",
       "      <td>790.697485</td>\n",
       "      <td>132.009995</td>\n",
       "      <td>197.869995</td>\n",
       "      <td>74.480003</td>\n",
       "      <td>173.070007</td>\n",
       "      <td>44.291095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181.500000</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>124.080002</td>\n",
       "      <td>324.989990</td>\n",
       "      <td>140.350006</td>\n",
       "      <td>223.639999</td>\n",
       "      <td>160.419998</td>\n",
       "      <td>145.679993</td>\n",
       "      <td>108.459999</td>\n",
       "      <td>16.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>82.490465</td>\n",
       "      <td>518.190002</td>\n",
       "      <td>90.886021</td>\n",
       "      <td>801.529758</td>\n",
       "      <td>132.949997</td>\n",
       "      <td>197.630005</td>\n",
       "      <td>74.860001</td>\n",
       "      <td>173.429993</td>\n",
       "      <td>44.467395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181.270004</td>\n",
       "      <td>122.790001</td>\n",
       "      <td>124.019997</td>\n",
       "      <td>328.579987</td>\n",
       "      <td>141.070007</td>\n",
       "      <td>224.410004</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>105.809998</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>170.839996</td>\n",
       "      <td>83.184994</td>\n",
       "      <td>517.280029</td>\n",
       "      <td>91.330092</td>\n",
       "      <td>806.821601</td>\n",
       "      <td>131.960007</td>\n",
       "      <td>198.210007</td>\n",
       "      <td>74.410004</td>\n",
       "      <td>171.529999</td>\n",
       "      <td>44.320476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182.800003</td>\n",
       "      <td>124.980003</td>\n",
       "      <td>128.119995</td>\n",
       "      <td>334.470001</td>\n",
       "      <td>140.479996</td>\n",
       "      <td>225.619995</td>\n",
       "      <td>159.729996</td>\n",
       "      <td>144.509995</td>\n",
       "      <td>107.379997</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>171.309998</td>\n",
       "      <td>84.504608</td>\n",
       "      <td>522.020020</td>\n",
       "      <td>91.320221</td>\n",
       "      <td>856.566582</td>\n",
       "      <td>134.660004</td>\n",
       "      <td>198.500000</td>\n",
       "      <td>73.900002</td>\n",
       "      <td>176.559998</td>\n",
       "      <td>44.594725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>183.369995</td>\n",
       "      <td>123.099998</td>\n",
       "      <td>126.699997</td>\n",
       "      <td>334.339996</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>223.740005</td>\n",
       "      <td>161.600006</td>\n",
       "      <td>145.309998</td>\n",
       "      <td>107.449997</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>173.660004</td>\n",
       "      <td>87.838357</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>92.741246</td>\n",
       "      <td>851.364321</td>\n",
       "      <td>134.639999</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>74.900002</td>\n",
       "      <td>175.820007</td>\n",
       "      <td>44.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>183.960007</td>\n",
       "      <td>123.139999</td>\n",
       "      <td>125.209999</td>\n",
       "      <td>337.480011</td>\n",
       "      <td>140.589996</td>\n",
       "      <td>222.020004</td>\n",
       "      <td>162.050003</td>\n",
       "      <td>147.169998</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>15.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>175.460007</td>\n",
       "      <td>87.262888</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>92.464932</td>\n",
       "      <td>879.723200</td>\n",
       "      <td>134.919998</td>\n",
       "      <td>201.250000</td>\n",
       "      <td>73.739998</td>\n",
       "      <td>176.240005</td>\n",
       "      <td>44.119999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>186.729996</td>\n",
       "      <td>125.930000</td>\n",
       "      <td>127.709999</td>\n",
       "      <td>351.320007</td>\n",
       "      <td>143.050003</td>\n",
       "      <td>226.449997</td>\n",
       "      <td>164.479996</td>\n",
       "      <td>148.919998</td>\n",
       "      <td>106.360001</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>179.990005</td>\n",
       "      <td>87.590308</td>\n",
       "      <td>530.099976</td>\n",
       "      <td>93.501090</td>\n",
       "      <td>884.567439</td>\n",
       "      <td>139.039993</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>179.449997</td>\n",
       "      <td>44.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>184.410004</td>\n",
       "      <td>122.930000</td>\n",
       "      <td>124.970001</td>\n",
       "      <td>339.309998</td>\n",
       "      <td>142.610001</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>164.259995</td>\n",
       "      <td>149.750000</td>\n",
       "      <td>104.680000</td>\n",
       "      <td>16.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>176.460007</td>\n",
       "      <td>87.828431</td>\n",
       "      <td>521.950012</td>\n",
       "      <td>94.497780</td>\n",
       "      <td>858.088455</td>\n",
       "      <td>136.059998</td>\n",
       "      <td>202.649994</td>\n",
       "      <td>75.629997</td>\n",
       "      <td>174.940002</td>\n",
       "      <td>44.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>184.899994</td>\n",
       "      <td>122.400002</td>\n",
       "      <td>125.639999</td>\n",
       "      <td>336.369995</td>\n",
       "      <td>142.899994</td>\n",
       "      <td>226.119995</td>\n",
       "      <td>163.580002</td>\n",
       "      <td>148.259995</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>174.130005</td>\n",
       "      <td>88.195544</td>\n",
       "      <td>517.909973</td>\n",
       "      <td>93.747798</td>\n",
       "      <td>860.000000</td>\n",
       "      <td>135.570007</td>\n",
       "      <td>199.289993</td>\n",
       "      <td>74.449997</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>43.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>183.740005</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>125.309998</td>\n",
       "      <td>334.119995</td>\n",
       "      <td>142.309998</td>\n",
       "      <td>226.360001</td>\n",
       "      <td>163.899994</td>\n",
       "      <td>150.350006</td>\n",
       "      <td>102.839996</td>\n",
       "      <td>15.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>172.160004</td>\n",
       "      <td>88.010002</td>\n",
       "      <td>520.690002</td>\n",
       "      <td>95.220001</td>\n",
       "      <td>845.090027</td>\n",
       "      <td>134.380005</td>\n",
       "      <td>201.960007</td>\n",
       "      <td>76.070000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>44.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>185.550003</td>\n",
       "      <td>121.379997</td>\n",
       "      <td>129.110001</td>\n",
       "      <td>334.359985</td>\n",
       "      <td>138.539993</td>\n",
       "      <td>227.220001</td>\n",
       "      <td>166.110001</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>102.589996</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>169.600006</td>\n",
       "      <td>87.239998</td>\n",
       "      <td>523.130005</td>\n",
       "      <td>95.669998</td>\n",
       "      <td>834.010010</td>\n",
       "      <td>133.699997</td>\n",
       "      <td>199.130005</td>\n",
       "      <td>75.290001</td>\n",
       "      <td>169.910004</td>\n",
       "      <td>43.869999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>186.830002</td>\n",
       "      <td>120.760002</td>\n",
       "      <td>129.330002</td>\n",
       "      <td>333.720001</td>\n",
       "      <td>138.869995</td>\n",
       "      <td>229.440002</td>\n",
       "      <td>164.979996</td>\n",
       "      <td>148.100006</td>\n",
       "      <td>102.199997</td>\n",
       "      <td>15.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>169.220001</td>\n",
       "      <td>87.349998</td>\n",
       "      <td>524.400024</td>\n",
       "      <td>96.220001</td>\n",
       "      <td>825.000000</td>\n",
       "      <td>133.100006</td>\n",
       "      <td>200.300003</td>\n",
       "      <td>74.089996</td>\n",
       "      <td>168.490005</td>\n",
       "      <td>43.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>185.889999</td>\n",
       "      <td>117.080002</td>\n",
       "      <td>128.630005</td>\n",
       "      <td>331.859985</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>227.479996</td>\n",
       "      <td>163.679993</td>\n",
       "      <td>148.440002</td>\n",
       "      <td>104.050003</td>\n",
       "      <td>15.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>173.389999</td>\n",
       "      <td>86.879997</td>\n",
       "      <td>522.650024</td>\n",
       "      <td>96.879997</td>\n",
       "      <td>828.679993</td>\n",
       "      <td>132.490005</td>\n",
       "      <td>202.559998</td>\n",
       "      <td>74.559998</td>\n",
       "      <td>169.830002</td>\n",
       "      <td>44.160000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0   178.440002  126.970001  127.010002  331.649994  139.550003  227.000000   \n",
       "1   177.899994  122.230003  123.010002  323.940002  140.669998  225.089996   \n",
       "2   181.500000  122.250000  124.080002  324.989990  140.350006  223.639999   \n",
       "3   181.270004  122.790001  124.019997  328.579987  141.070007  224.410004   \n",
       "4   182.800003  124.980003  128.119995  334.470001  140.479996  225.619995   \n",
       "5   183.369995  123.099998  126.699997  334.339996  143.000000  223.740005   \n",
       "6   183.960007  123.139999  125.209999  337.480011  140.589996  222.020004   \n",
       "7   186.729996  125.930000  127.709999  351.320007  143.050003  226.449997   \n",
       "8   184.410004  122.930000  124.970001  339.309998  142.610001  227.000000   \n",
       "9   184.899994  122.400002  125.639999  336.369995  142.899994  226.119995   \n",
       "10  183.740005  120.000000  125.309998  334.119995  142.309998  226.360001   \n",
       "11  185.550003  121.379997  129.110001  334.359985  138.539993  227.220001   \n",
       "12  186.830002  120.760002  129.330002  333.720001  138.869995  229.440002   \n",
       "13  185.889999  117.080002  128.630005  331.859985  139.000000  227.479996   \n",
       "\n",
       "            6           7           8          9   ...          38         39  \\\n",
       "0   158.100006  144.009995  106.790001  15.630000  ...  167.350006  83.135394   \n",
       "1   158.500000  145.339996  108.769997  16.040001  ...  171.479996  81.885236   \n",
       "2   160.419998  145.679993  108.459999  16.010000  ...  171.000000  82.490465   \n",
       "3   160.000000  147.000000  105.809998  15.950000  ...  170.839996  83.184994   \n",
       "4   159.729996  144.509995  107.379997  15.800000  ...  171.309998  84.504608   \n",
       "5   161.600006  145.309998  107.449997  15.900000  ...  173.660004  87.838357   \n",
       "6   162.050003  147.169998  105.500000  15.880000  ...  175.460007  87.262888   \n",
       "7   164.479996  148.919998  106.360001  16.100000  ...  179.990005  87.590308   \n",
       "8   164.259995  149.750000  104.680000  16.020000  ...  176.460007  87.828431   \n",
       "9   163.580002  148.259995  102.500000  15.700000  ...  174.130005  88.195544   \n",
       "10  163.899994  150.350006  102.839996  15.570000  ...  172.160004  88.010002   \n",
       "11  166.110001  150.250000  102.589996  15.630000  ...  169.600006  87.239998   \n",
       "12  164.979996  148.100006  102.199997  15.460000  ...  169.220001  87.349998   \n",
       "13  163.679993  148.440002  104.050003  15.550000  ...  173.389999  86.879997   \n",
       "\n",
       "            40         41          42          43          44         45  \\\n",
       "0   514.510010  90.649184  785.634520  132.750000  196.960007  73.639999   \n",
       "1   512.500000  91.280745  790.697485  132.009995  197.869995  74.480003   \n",
       "2   518.190002  90.886021  801.529758  132.949997  197.630005  74.860001   \n",
       "3   517.280029  91.330092  806.821601  131.960007  198.210007  74.410004   \n",
       "4   522.020020  91.320221  856.566582  134.660004  198.500000  73.900002   \n",
       "5   525.000000  92.741246  851.364321  134.639999  202.000000  74.900002   \n",
       "6   529.000000  92.464932  879.723200  134.919998  201.250000  73.739998   \n",
       "7   530.099976  93.501090  884.567439  139.039993  205.000000  74.750000   \n",
       "8   521.950012  94.497780  858.088455  136.059998  202.649994  75.629997   \n",
       "9   517.909973  93.747798  860.000000  135.570007  199.289993  74.449997   \n",
       "10  520.690002  95.220001  845.090027  134.380005  201.960007  76.070000   \n",
       "11  523.130005  95.669998  834.010010  133.699997  199.130005  75.290001   \n",
       "12  524.400024  96.220001  825.000000  133.100006  200.300003  74.089996   \n",
       "13  522.650024  96.879997  828.679993  132.490005  202.559998  74.559998   \n",
       "\n",
       "            46         47  \n",
       "0   171.169998  43.801366  \n",
       "1   173.070007  44.291095  \n",
       "2   173.429993  44.467395  \n",
       "3   171.529999  44.320476  \n",
       "4   176.559998  44.594725  \n",
       "5   175.820007  44.900002  \n",
       "6   176.240005  44.119999  \n",
       "7   179.449997  44.220001  \n",
       "8   174.940002  44.029999  \n",
       "9   172.500000  43.470001  \n",
       "10  170.000000  44.099998  \n",
       "11  169.910004  43.869999  \n",
       "12  168.490005  43.500000  \n",
       "13  169.830002  44.160000  \n",
       "\n",
       "[14 rows x 48 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
